{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Winning Jeopardy\n",
    "\n",
    "Jeopardy is a popular TV show in the US where participants answer questions to win money.\n",
    "\n",
    "In this project, I'll work with a dataset of Jeopardy questions to figure out some patterns in the questions that could help you win.\n",
    "\n",
    "The dataset contains 20000 rows from the beginning of a full dataset of Jeopardy questions, which can be downloaded [here](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/).\n",
    "\n",
    "### Summary of results:\n",
    "- There are about 6% of the answers are contained in the question itself. The percentage is really low, it means if there are 100 words in the answer, only in average 6 of them world appear in the question. It's not reasonable to find the answer in the question.\n",
    "- There are about 69% of the terms in a question have been repeated. The percentage is quite hight and it affects the studying strategy for Jeopardy because most of the terms used in the past are likely to appear in the future questions.\n",
    "- None of the terms had a significant difference in usage between high value and low value questions. Additionally, the frequencies were all lower than 5, so the chi-squared test isn't as valid. It would be better to run this test with only terms that have higher frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19999, 7)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read in dataset\n",
    "data = pd.read_csv('jeopardy.csv')\n",
    "\n",
    "# quick exploration of the dataset\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data\n",
    "### Removing unnecessary spaces in columns names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the cloumn names contain spaces in front and I am going to remove the spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.columns = ['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question', 'Answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing text columns\n",
    "I am going to normalize the text columns in this session by using a defined function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_text(text):\n",
    "    '''\n",
    "    function converting the string to lowercase and removing all punctuation in the string.\n",
    "    '''\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^0-9a-z\\s]', '', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apply function to Question column\n",
    "data['clean_question'] = data['Question'].apply(normalize_text)\n",
    "\n",
    "# apply function to Answer column\n",
    "data['clean_answer'] = data['Answer'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing value columns\n",
    "I am going to normalize the value columns in this session by using a defined function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_value(text):\n",
    "    '''\n",
    "    function removing all punctuation in the string and converting the string to integer.\n",
    "    ff the conversion has an error, assign 0 instead.\n",
    "    '''\n",
    "    text = re.sub('[^0-9\\s]', '', text)\n",
    "    try:\n",
    "        text = int(text)\n",
    "    except Exception:\n",
    "        text = 0\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apply function to Value column\n",
    "data['clean_value'] = data['Value'].apply(normalize_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Air Date column to datetime format\n",
    "I am going to convert the Air Date columns to datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Air Date'] = pd.to_datetime(data['Air Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Studying past questions\n",
    "\n",
    "To study past questions, it would be helpful to figure out two things:\n",
    "\n",
    "- How often the answer is deducible from the question.\n",
    "- How often new questions are repeats of older questions.\n",
    "\n",
    "The first question can be answered by seeing how many times words in the answer also occur in the question.\n",
    "The second question can be answered by seeing how often complex words (> 6 characters) reoccur.\n",
    "\n",
    "I will work on the first question first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deducible questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_answer_in_question(row):\n",
    "    '''\n",
    "    function to split answer and question to a series and find out \n",
    "    if the answer is existing in the question,\n",
    "    return proportion of answer existing in questions\n",
    "    '''\n",
    "    split_answer = row['clean_answer'].split()\n",
    "    split_question = row['clean_question'].split()\n",
    "    match_count = 0\n",
    "    if 'the' in split_answer:\n",
    "        split_answer.remove('the') # 'the' is common but useless\n",
    "    if len(split_answer) == 0:\n",
    "        return 0 # to avoid division by zero error later\n",
    "    for item in split_answer:\n",
    "        if item in split_question:\n",
    "            match_count += 1\n",
    "    return match_count / len(split_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05900196524977763"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply function to dataset\n",
    "answer_in_question = data.apply(count_answer_in_question, axis = 1)\n",
    "\n",
    "# find the mean of number of answer in question\n",
    "answer_in_question.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are about 6% of the answers are contained in the question itself. The percentage is really low, it means if there are 100 words in the answer, only in average 6 of them world appear in the question. It's not reasonable to find the answer in the question.\n",
    "\n",
    "Then I will investigate how often new questions are repeats of older ones. With the existing dataset, it's not possible to answer this question completely, because the dataset contains only 10% of the full Jeopardy question dataset, but I will still investigate it as practice.\n",
    "\n",
    "The repetition of the word is determined by words with 6 or more characters, because works like 'the' or 'than' are commonly used, but do not provide a lot of information about the question. If the term has been used again in the later question, it's considered as repeated question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeated questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6876260592169802"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty list for repeated question\n",
    "question_overlap = []\n",
    "\n",
    "# empty list for used termss\n",
    "terms_used = set()\n",
    "\n",
    "# sort data by ascending air date\n",
    "data = data.sort_values(['Air Date'])\n",
    "\n",
    "for row in data.iterrows():\n",
    "    row = row[1]\n",
    "    split_question = row['clean_question'].split()\n",
    "    split_question = [q for q in split_question if len(q) > 5]\n",
    "    match_count = 0\n",
    "    for word in split_question:\n",
    "        if word in terms_used:\n",
    "            match_count += 1\n",
    "    for word in split_question:\n",
    "        terms_used.add(word)\n",
    "        \n",
    "    if len(split_question) > 0:\n",
    "        match_count = match_count / len(split_question)\n",
    "    question_overlap.append(match_count)\n",
    "    \n",
    "# assign question_overlap to data\n",
    "data['question_overlap'] = question_overlap\n",
    "\n",
    "# find mean of question overlap column\n",
    "data['question_overlap'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There are about 69% of the terms in a question have been repeated. The percentage is quite hight and it affects the studying strategy for Jeopardy because most of the terms used in the past are likely to appear in the future questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High value questions\n",
    "There is a strategy that only study questions that pertain to high value questions instead of low value questions. In this session, I am going to figure out which terms correspond to high-value questions using a chi-squared test. The questions are separated as following:\n",
    "\n",
    "- Low value -- Any row where Value is less than 800.\n",
    "- High value -- Any row where Value is greater than 800."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def define_value(row):\n",
    "    '''\n",
    "    function to define if that question is high value/low value\n",
    "    '''\n",
    "    if row['clean_value'] > 800:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "    return value\n",
    "\n",
    "# apply function to dataset\n",
    "data['high_value'] = data.apply(define_value, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def value_counts(word):\n",
    "    '''\n",
    "    function to count high value terms and low value terms\n",
    "    '''\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for row in data.iterrows():\n",
    "        row = row[1]\n",
    "        split_question = row['clean_question'].split()\n",
    "        if word in split_question:\n",
    "            if row['high_value'] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 2),\n",
       " (0, 1),\n",
       " (0, 2),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (0, 2),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (1, 3)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import sample\n",
    "\n",
    "# randomly pick 10 elements for comparsion\n",
    "comparison_terms = []\n",
    "comparison_terms.append(sample(terms_used, 10)) # or choice\n",
    "comparison_terms = comparison_terms[0]\n",
    "\n",
    "# from random import choice\n",
    "\n",
    "# terms_used_list = list(terms_used)\n",
    "# comparison_terms = [choice(terms_used_list) for _ in range(10)]\n",
    "\n",
    "# empty list for observed and expected value\n",
    "observed_expected = []\n",
    "\n",
    "# apply function to comparison terms to find out observed count\n",
    "for term in comparison_terms:\n",
    "    observed_expected.append(value_counts(term))\n",
    "    \n",
    "observed_expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I've found the observed counts for a few terms, the expected counts and the chi-squared value can be computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=2.3995960878537224, pvalue=0.12136658322360773),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.803925692253768, pvalue=0.3699222378079571),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.803925692253768, pvalue=0.3699222378079571),\n",
       " Power_divergenceResult(statistic=2.487792117195675, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=0.4448774816612795, pvalue=0.5047776487545996),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.02636443308440769, pvalue=0.871013484688921)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "# separate high value set and low value set\n",
    "high_value_count = len(data[data['high_value'] == 1])\n",
    "low_value_count = len(data[data['high_value'] == 0])\n",
    "\n",
    "# empty list for chi squared values\n",
    "chi_squared = []\n",
    "\n",
    "for obs_list in observed_expected:\n",
    "    total = np.sum(obs_list)\n",
    "    total_prop = total / len(data)\n",
    "    high_value_exp = total_prop * high_value_count\n",
    "    low_value_exp = total_prop * low_value_count\n",
    "    observed = np.array([obs_list[0], obs_list[1]])\n",
    "    expected = np.array([high_value_exp, low_value_exp])\n",
    "    chi_squared.append(chisquare(observed, expected))\n",
    "\n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the terms had a significant difference in usage between high value and low value rows. Additionally, the frequencies were all lower than 5, so the chi-squared test isn't as valid. It would be better to run this test with only terms that have higher frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this project, I have the following findings:\n",
    "- There are about 6% of the answers are contained in the question itself. The percentage is really low, it means if there are 100 words in the answer, only in average 6 of them world appear in the question. It's not reasonable to find the answer in the question.\n",
    "- There are about 69% of the terms in a question have been repeated. The percentage is quite hight and it affects the studying strategy for Jeopardy because most of the terms used in the past are likely to appear in the future questions.\n",
    "- None of the terms had a significant difference in usage between high value and low value questions. Additionally, the frequencies were all lower than 5, so the chi-squared test isn't as valid. It would be better to run this test with only terms that have higher frequencies.\n",
    "\n",
    "## Further Study\n",
    "Here are some potential next steps:\n",
    "\n",
    "- Find a better way to eliminate non-informative words than just removing words that are less than 6 characters long. Some ideas:\n",
    "    - Manually create a list of words to remove, like the, than, etc.\n",
    "    - Find a list of stopwords to remove.\n",
    "    - Remove words that occur in more than a certain percentage (like 5%) of questions.\n",
    "- Perform the chi-squared test across more terms to see what terms have larger differences. This is hard to do currently because the code is slow, but here are some ideas:\n",
    "    - Use the apply method to make the code that calculates frequencies more efficient.\n",
    "    - Only select terms that have high frequencies across the dataset, and ignore the others.\n",
    "- Look more into the Category column and see if any interesting analysis can be done with it. Some ideas:\n",
    "    - See which categories appear the most often.\n",
    "    - Find the probability of each category appearing in each round.\n",
    "- Use the whole Jeopardy dataset (available here) instead of the subset we used in this mission.\n",
    "- Use phrases instead of single words when seeing if there's overlap between questions. Single words don't capture the whole context of the question well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
